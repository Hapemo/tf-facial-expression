{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a75ea4e-7044-4150-b59e-d3a38ad33473",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import multiprocessing\n",
    "from keras.backend import set_session\n",
    "from keras.backend import clear_session\n",
    "from keras.backend import get_session\n",
    "import time\n",
    "from datetime import timedelta \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907266e0-f1c0-42be-9f29-1c37d31d2117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable gpu to use cpu\n",
    "# tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09c8764-0ae0-4887-99b5-a631e85a3222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    # tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "    # config = tf.compat.v1.ConfigProto()\n",
    "    # config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "    # keras.set_session(tf.Session(config=config))\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a0796a-7779-40f1-a077-c013999ee3e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup working directory\n",
    "emotionList = ('Neutral', 'Happy', 'Sad', 'Surprise', 'Fear', 'Disgust', 'Anger', 'Contempt')\n",
    "# limitCounter = [0,0,0,0,0,0,0,0]\n",
    "\n",
    "\n",
    "def Setup():\n",
    "  os.chdir(\"C:\\\\Users\\\\j.teoh\\\\Desktop\\\\tflite-facial-expression\") # change working directory\n",
    "\n",
    "# currently limited to 19999 images\n",
    "# Load the images into a nested list containing info of image in tuple format (label, image name)\n",
    "def LoadAllImageNames(imageFiles, limit = 0, catLimit = []*8):\n",
    "  limitCounter = [0,0,0,0,0,0,0,0]\n",
    "  trainingSet = []\n",
    "  loadCounter = 0\n",
    "  for file in imageFiles:\n",
    "    if (limit > 0 and loadCounter > limit):\n",
    "      break\n",
    "  \n",
    "    name = file.name[:-4] # file name w/o file extension\n",
    "    data = np.load(\"train_set\\\\annotations\\\\{}_exp.npy\".format(name))\n",
    "    label = int(data.item(0))\n",
    "\n",
    "    if limitCounter[label] >= catLimit[label]:\n",
    "      continue\n",
    "    limitCounter[label] += 1\n",
    "    loadCounter += 1\n",
    "\n",
    "    trainingSet.append((label, file.name))\n",
    "    if (loadCounter%10000==0):\n",
    "      print(\"Files loaded:{}\".format(loadCounter))\n",
    "  print(\"Total images loaded: \", loadCounter)\n",
    "  print(\"Images Loaded: \", limitCounter)\n",
    "  random.shuffle(trainingSet)\n",
    "  return trainingSet\n",
    "\n",
    "# Load the images into a nested list containing info of image in tuple format (label, image name)\n",
    "def LoadAllTestImageNames(imageFiles):\n",
    "  testingSet = []\n",
    "  loadCounter = 0\n",
    "  for file in imageFiles:\n",
    "    loadCounter += 1\n",
    "    if (loadCounter%10000==0):\n",
    "      print(\"Files loaded:{}\".format(loadCounter))\n",
    "    name = file.name[:-4] # file name w/o file extension\n",
    "    data = np.load(\"val_set\\\\annotations\\\\{}_exp.npy\".format(name))\n",
    "    label = int(data.item(0))\n",
    "    if label != 1 and label != 2 and label != 6:\n",
    "        continue\n",
    "    testingSet.append((label, file.name))\n",
    "\n",
    "  random.shuffle(testingSet)\n",
    "\n",
    "  return testingSet\n",
    "\n",
    "# Load the pixels of a picture to numpy.ndarray format. false for test set, true for training set\n",
    "# Return image in RGB format\n",
    "def LoadImage(imageName, trainingSetBool, normalize = True):\n",
    "  intermediatePath = str()\n",
    "  if (trainingSetBool):\n",
    "    intermediatePath = \"\\\\train_set\\\\images\\\\\"\n",
    "  else:\n",
    "    intermediatePath = \"\\\\val_set\\\\images\\\\\"\n",
    "  if normalize:\n",
    "    image_array = cv2.imread(\"{}{}{}\".format(os.getcwd(), intermediatePath, imageName))\n",
    "    image_array = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)\n",
    "    image_array = image_array/255\n",
    "  else:\n",
    "    image_array = cv2.imread(\"{}{}{}\".format(os.getcwd(), intermediatePath, imageName))\n",
    "    image_array = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)\n",
    "  return image_array\n",
    "\n",
    "# Extract the daata from 0 to amount from list and return it\n",
    "def CropData(list, amount):\n",
    "  if (len(list) < amount):\n",
    "    amount = len(list)\n",
    "  croppedList = list[:amount]\n",
    "  del list[:amount]\n",
    "  return croppedList\n",
    "\n",
    "def LoadImages(list, trainingSetBool):\n",
    "  label = []\n",
    "  data = []\n",
    "  count = 0\n",
    "  for entries in list:\n",
    "    try:\n",
    "      image = LoadImage(entries[1], trainingSetBool)\n",
    "      data.append(image) \n",
    "      label.append(entries[0]) \n",
    "    except: \n",
    "      print(\"Failed to load training image: \", entries[ 1])\n",
    "  npLabel = np.array(label) \n",
    "  npData = np.array(data) \n",
    "  return npLabel, npData \n",
    "\n",
    "def InitializeModel():\n",
    "  pretrained_model = tf.keras.applications.MobileNetV3Large(input_shape=(224,224,3)) # Initializing model with mobile net V3 pretrained model\n",
    "\n",
    "  # Initializing the input and output from the model, removing last layer\n",
    "  base_input = pretrained_model.layers[0].input\n",
    "  base_output = pretrained_model.layers[-2].output\n",
    "\n",
    "  # Adding 3 more layers to output side\n",
    "  final_output = layers.Dense(128)(base_output) # Adding new layers, to the output side\n",
    "  final_output = layers.Activation('relu')(final_output) # activating layer\n",
    "  final_output = layers.Dense(64)(final_output)\n",
    "  final_output = layers.Activation('relu')(final_output) # activating layer\n",
    "  final_output = layers.Dense(8, activation = 'softmax')(final_output) # 8 cuz there are 8 image classifications\n",
    "\n",
    "  new_model = keras.Model(inputs = base_input, outputs = final_output)\n",
    "  return new_model\n",
    "\n",
    "def ConvertToGray(image):\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "  return image\n",
    "\n",
    "def ScaleImage(image, width):\n",
    "  ratio = image.shape[1]/width\n",
    "  image = cv2.resize(image, (width, int(image.shape[0]/ratio)))\n",
    "  return image\n",
    "\n",
    "def DetectFace(image):\n",
    "  face_roi = np.ndarray(1)\n",
    "  faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "  grayImage = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "  faces = faceCascade.detectMultiScale(grayImage, 1.3, 5)\n",
    "  for x,y,w,h in faces:\n",
    "    roi_gray = grayImage[y:y+h, x:x+w]\n",
    "    roi_color = image[y:y+h, x:x+w]\n",
    "    cv2.rectangle(image, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "    facess = faceCascade.detectMultiScale(roi_gray)\n",
    "    if (len(facess) == 0):\n",
    "      print(\"Face not detected\")\n",
    "    else:\n",
    "      for (ex,ey,ew,eh) in facess:\n",
    "        face_roi = roi_color[ey:ey+eh, ex:ex+ew]\n",
    "  return face_roi\n",
    "\n",
    "def ConvertToInput(image):\n",
    "  input = ScaleImage(image, 224)\n",
    "  input = np.expand_dims(input, axis = 0) ## to add fourth dimension to fit model input\n",
    "  input = input/255\n",
    "  return input\n",
    "\n",
    "def GetResult(model, input):\n",
    "  Predictions = model.predict(input)\n",
    "  print(Predictions)\n",
    "  result = np.argmax(Predictions)\n",
    "  return emotionList[result]\n",
    "\n",
    "# Reset Keras Session\n",
    "def reset_keras():\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    "\n",
    "    # try:\n",
    "    #     del classifier # this is from global space - change this as you need\n",
    "    # except:\n",
    "    #     pass\n",
    "\n",
    "    # use the same config as you used to create the session\n",
    "    tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.9, visible_device_list=\"0\")\n",
    "\n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "  def on_train_begin(self, logs={}):\n",
    "    self.times = []\n",
    "\n",
    "  def on_epoch_begin(self, batch, logs={}):\n",
    "    self.epoch_time_start = time.time()\n",
    "\n",
    "  def on_epoch_end(self, batch, logs={}):\n",
    "    self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "  def AverageTime(self):\n",
    "    sum = 0\n",
    "    for time in self.times:\n",
    "      sum += time\n",
    "    return sum/len(self.times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8075535-75ed-424a-b01b-2689f93c99b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get currect directory (os.getcwd() -> C:\\Users\\jazzt\\src)\n",
    "\n",
    "#-----------------------Start of code---------------------------\n",
    "# Path directories\n",
    "Setup()\n",
    "\n",
    "# initialise image names and label\n",
    "imageFiles = os.scandir(\"train_set\\\\images\")\n",
    "trainingSetData = LoadAllImageNames(imageFiles, catLimit=[3000]*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d25910",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = tf.keras.applications.MobileNetV3Large(input_shape=(224,224,3)) # Initializing model with mobile net V3 pretrained model\n",
    "\n",
    "# Initializing the input and output from the model, removing last layer\n",
    "base_input = pretrained_model.layers[0].input\n",
    "base_output = pretrained_model.layers[-2].output\n",
    "\n",
    "# Adding 3 more layers to output side\n",
    "final_output = layers.Dense(128)(base_output) # Adding new layers, to the output side\n",
    "final_output = layers.Activation('relu')(final_output) # activating layer\n",
    "final_output = layers.Dense(8, activation = 'softmax')(final_output) # 8 cuz there are 8 image classifications\n",
    "\n",
    "model = keras.Model(inputs = base_input, outputs = final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7099e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "time_callback = TimeHistory()\n",
    "dataSet = trainingSetData.copy()\n",
    "\n",
    "# train model\n",
    "batchSize = 48\n",
    "imgPerIter = batchSize*16\n",
    "count = 0\n",
    "while(len(dataSet) != 0):\n",
    "  # training data\n",
    "  croppedList = []\n",
    "  try:\n",
    "    croppedList = CropData(dataSet, imgPerIter)\n",
    "    print(\"loading image\")\n",
    "    label, data = LoadImages(croppedList, True)\n",
    "    model.fit(data, label, epochs = 11, batch_size = batchSize, callbacks = [time_callback])\n",
    "    print(time_callback.AverageTime())\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "  \n",
    "  model.save_weights('bs48_128Dense.h5')\n",
    "  count = count + len(croppedList)\n",
    "  timeLeft = len(dataSet)/imgPerIter * time_callback.AverageTime()\n",
    "  print(\"trained image count: \", count)\n",
    "  print(\"Images Left: \", len(dataSet))\n",
    "  print(\"Estimated completion time: \", str(timedelta(seconds=timeLeft)))\n",
    "  reset_keras()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6705e1-6640-4ffc-bed9-b7fe86e66533",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Default loading in model and training with reset of keras in GPU every iteration\n",
    "# initialise model\n",
    "model = InitializeModel()\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# train model\n",
    "\n",
    "batchSize = 48\n",
    "imgPerIter = batchSize*16\n",
    "count = 0\n",
    "while(len(trainingSetData) != 0):\n",
    "  # training data\n",
    "  try:\n",
    "    croppedList = CropData(trainingSetData, imgPerIter)\n",
    "    print(\"loading image\")\n",
    "    label, data = LoadImages(croppedList, True)\n",
    "    model.fit(data, label, epochs = 11, batch_size = batchSize)\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "  \n",
    "  model.save_weights('label126Limited6BatchSize48gpu.h5')\n",
    "  count = count + imgPerIter\n",
    "  print(\"trained image count: \", count)\n",
    "  reset_keras()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e002a5-3092-4337-9155-76eec5b69262",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load and save weights every iter, reset gpu memory with cuda (will break the program)\n",
    "\n",
    "\n",
    "# train model\n",
    "\n",
    "count = 0\n",
    "while(len(trainingSetData) != 0):\n",
    "  model = InitializeModel()\n",
    "  model.load_weights(\"feModelWeights2feb.h5\")\n",
    "  model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics=[\"accuracy\"])\n",
    "  # training data\n",
    "  try:\n",
    "    croppedList = CropData(trainingSetData, 1000)\n",
    "    print(\"loading image\")\n",
    "    label, data = LoadImages(croppedList, True)\n",
    "    model.fit(data, label, epochs = 11, batch_size = 32)\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "  \n",
    "  model.save_weights('feModelWeights2feb.h5')\n",
    "  count = count + 1\n",
    "  print(\"trained image count: \", count*1000)\n",
    "  cuda.get_current_device().reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbdbd23-abe8-47d6-bb45-e553efda886a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2188cfd0-939d-41bc-b9da-317bdab48d4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#using multiprocessor to run model\n",
    "# train model\n",
    "count = 0\n",
    "while(len(trainingSetData) != 0):\n",
    "\n",
    "    croppedList = CropData(trainingSetData, 1000)\n",
    "    print(\"loading image\")\n",
    "    p = multiprocessing.Process(target = trainModel, args=(croppedList))\n",
    "    p.start()\n",
    "    p.join()\n",
    "    \n",
    "  \n",
    "    count = count + 1\n",
    "    print(\"trained image count: \", count*1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66853953-bd88-4660-8fd7-81d25cba28b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Default loading and training of model, extracting lower half of data only\n",
    "\n",
    "#-----------------------Start of code---------------------------\n",
    "# Path directories\n",
    "Setup()\n",
    "\n",
    "# initialise image names and label\n",
    "imageFiles = os.scandir(\"train_set\\\\images\")\n",
    "trainingSetData = LoadAllImageNames(imageFiles)\n",
    "\n",
    "# initialise model\n",
    "model = InitializeModel()\n",
    "model.load_weights(\"feModelWeights5feb.h5\")\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics=[\"accuracy\"])\n",
    "trainingSetData = trainingSetData[(120000+161000):]\n",
    "\n",
    "# train model\n",
    "count = 0\n",
    "while(len(trainingSetData) != 0):\n",
    "  # training data\n",
    "  try:\n",
    "    croppedList = CropData(trainingSetData, 1000)\n",
    "    print(\"loading image\")\n",
    "    label, data = LoadImages(croppedList, True)\n",
    "    model.fit(data, label, epochs = 11, batch_size = 32)\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "  \n",
    "  model.save_weights('feModelWeights6feb.h5')\n",
    "  count = count + 1\n",
    "  print(\"trained image count: \", count*1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6ebede-94d8-42f4-9266-07ccbbfbaadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of data in each facial expression\n",
    "imageFiles = os.scandir(\"train_set\\\\images\")\n",
    "trainingSetData = LoadAllImageNames(imageFiles)\n",
    "\n",
    "counterList = list(range(8))\n",
    "for label, name in trainingSetData:\n",
    "    counterList[label] += 1\n",
    "    \n",
    "print(counterList)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a6a483-334c-41cf-8aeb-f1ea038d7a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = 0\n",
    "for i in counterList:\n",
    "    sum += i\n",
    "\n",
    "for i in range(len(counterList)):\n",
    "    counterList[i] /= sum\n",
    "\n",
    "print(counterList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb9597d-0739-4ca3-a564-bb0146c45775",
   "metadata": {},
   "outputs": [],
   "source": [
    "croppedList = CropData(trainingSetData, 1000)\n",
    "label, data = LoadImages(croppedList, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25148821-b21c-43ee-9f5f-f3647d2898db",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = InitializeModel()\n",
    "print(model.summary())\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1638ff68-56e3-4779-8995-660d1581b103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = InitializeModel()\n",
    "print(model.summary())\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd15b1d5-b1c7-41fc-a938-9cbe5f3f1d91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(data, label, epochs = 13, batch_size = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fc8dd0-074a-42dd-ae64-4e395ab45f7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing trained model\n",
    "image = LoadImage(\"3.jpg\", False, normalize = False)\n",
    "# image = cv2.resize(image, (224,224))\n",
    "image = ScaleImage(image, 224)\n",
    "\n",
    "face = DetectFace(image)\n",
    "\n",
    "plt.imshow(face)\n",
    "\n",
    "preppedInput = ConvertToInput(face)\n",
    "result = GetResult(model, preppedInput)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fce379-adfc-4815-804d-c9baaf1a39b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551a660c-2224-497d-a4b5-e06cbf4ae544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# testing loading in data from tar using tensorflow\n",
    "os.chdir(\"C:\\\\Users\\\\j.teoh\\\\Desktop\\\\tflite-facial-expression\") # change working directory\n",
    "img_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, rotation_range=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f4648c-69c7-45df-8e95-37c1fec209e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images, labels = next(img_gen.flow_from_directory(\"train_set.tar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eaf62b-2632-43fa-a535-3e56764e5394",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "croppedList = CropData(trainingSetData, 1000)\n",
    "label, data = LoadImages(croppedList, True)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data,label)).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a39fe4e-7f8d-46ab-bb09-37ab517c1731",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show(image, label):\n",
    "  plt.figure()\n",
    "  plt.imshow(image)\n",
    "  plt.title(label)\n",
    "  plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bb5f2b-4139-4439-a730-bc03139569ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = InitializeModel()\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c1dd45-9738-4129-832c-6b5d981f2007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(dataset.repeat(), epochs=11, steps_per_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8c5782-12fa-4d90-9fac-f6a3ff6f1d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing model\n",
    "Setup()\n",
    "\n",
    "modelNames = [\"label126Limited6BatchSize48gpu.h5\"]\n",
    "model = InitializeModel()\n",
    "mainData = LoadAllTestImageNames(os.scandir(\"val_set\\\\images\"))\n",
    "resultPool =[]\n",
    "\n",
    "for modelName in modelNames:\n",
    "    model.load_weights(modelName)\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    # initialise image names and label\n",
    "    testSetData = []\n",
    "    testSetData.extend(mainData)\n",
    "    # print(mainData)\n",
    "    # test model\n",
    "    lostSum = 0\n",
    "    accuracySum = 0\n",
    "    count = 0\n",
    "    while(len(testSetData) != 0):\n",
    "      # training data\n",
    "      # try:\n",
    "      croppedList = CropData(testSetData, 100)\n",
    "      print(\"loading image\")\n",
    "      label, data = LoadImages(croppedList, False)\n",
    "      result = model.evaluate(data, label, batch_size = 1)\n",
    "      lostSum += result[0]\n",
    "      accuracySum += result[1]\n",
    "      # except:\n",
    "      #   print(\"Failed to train data\")\n",
    "\n",
    "      count += 1\n",
    "      reset_keras()\n",
    "      # print(count)\n",
    "    # print(mainData)\n",
    "    print(\"==========FINISH TESTING===========\")\n",
    "    print(\"model name: \", modelName)\n",
    "    print(\"average lost: \", lostSum/count)\n",
    "    print(\"average accuracy: \", accuracySum/count)\n",
    "    resultPool.append((modelName, lostSum/count, accuracySum/count))\n",
    "    \n",
    "print(resultPool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d07458",
   "metadata": {},
   "source": [
    "## Setting up image with Keras for MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebe1de8-8627-440c-9cab-7626a70eb46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "Setup()\n",
    "# preparing dataset of 1000 images\n",
    "dataset = trainingSetData[:1000].copy()\n",
    "trainingSet = []\n",
    "for label, fileName in dataset:\n",
    "    # Load image and convert to 224,224,3 nested array\n",
    "    tempImg = image.load_img(\"train_set\\\\images\\\\\"+fileName, target_size = (224,224))\n",
    "    tempImg = image.img_to_array(tempImg)\n",
    "    \n",
    "    # turn all the values in nested array into value between -1 and 1\n",
    "    trainingSet.append(preprocess_input(tempImg))\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7768abd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2261c364",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
