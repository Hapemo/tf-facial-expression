{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from keras.backend import clear_session\n",
    "from keras.backend import get_session\n",
    "import time\n",
    "from datetime import timedelta \n",
    "\n",
    "import math\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "os.chdir(\"..\\\\asset\") # change working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "emotionList = ('Neutral', 'Happy', 'Sad', 'Surprise', 'Fear', 'Disgust', 'Anger', 'Contempt')\n",
    "TRAINANNOTATIONPATH = \"train_set\\\\annotations\\\\\"\n",
    "TRAINIMAGEPATH = \"train_set\\\\images\\\\\"\n",
    "TESTANNOTATIONPATH = \"val_set\\\\annotations\\\\\"\n",
    "TESTIMAGEPATH = \"val_set\\\\images\\\\\"\n",
    "\n",
    "def LoadAllImageNames(filePath, limit = 0, catLimit = []):\n",
    "  \"\"\"Load the images names and label in tuple format (label, image name)\n",
    "\n",
    "  Args:\n",
    "      filePath (str): directory of image folder\n",
    "      limit (int, optional): max number of image to load. Defaults to 0.\n",
    "      catLimit (list<int>, optional): array of image count limit for each class. Defaults to []*8.\n",
    "\n",
    "  Returns:\n",
    "      list<str>: shuffled list of image names\n",
    "  \"\"\"\n",
    "  limitCounter = [0,0,0,0,0,0,0,0]\n",
    "  dataSet = []\n",
    "  loadCounter = 0\n",
    "  for file in os.scandir(filePath):\n",
    "    if (limit > 0 and loadCounter > limit):\n",
    "      break\n",
    "  \n",
    "    name = file.name[:-4] # file name w/o file extension\n",
    "    data = np.load(\"{}{}_exp.npy\".format(TRAINANNOTATIONPATH if filePath == TRAINIMAGEPATH else TESTANNOTATIONPATH, name)) # \n",
    "    label = int(data.item(0))\n",
    "\n",
    "    if len(catLimit) > 0 and limitCounter[label] >= catLimit[label]:\n",
    "        continue\n",
    "    limitCounter[label] += 1\n",
    "    loadCounter += 1\n",
    "\n",
    "    dataSet.append((label, file.name))\n",
    "    if (loadCounter%10000==0):\n",
    "      print(\"Files loaded:{}\".format(loadCounter))\n",
    "  \n",
    "  print(\"Total images loaded: \", loadCounter)\n",
    "  print(\"Images Loaded: \", limitCounter)\n",
    "  random.shuffle(dataSet)\n",
    "  return dataSet\n",
    "\n",
    "# Load the pixels of a picture to numpy.ndarray format. false for test set, true for training set\n",
    "# Return image in RGB format\n",
    "def LoadImage(imagePath, imageName, normalize = True):\n",
    "  \"\"\"Load image using numpy\n",
    "\n",
    "  Args:\n",
    "      imagePath (str): image path \n",
    "      imageName (str): image name\n",
    "      normalize (bool, optional): To normalize image or not. Defaults to True.\n",
    "\n",
    "  Returns:\n",
    "      numpy array: x,y,3 array\n",
    "  \"\"\"\n",
    "  # print(\"{}{}{}\".format(os.getcwd(), \"\\\\\"+imagePath, imageName))\n",
    "  image_array = cv2.imread(\"{}{}{}\".format(os.getcwd(), \"\\\\\"+imagePath, imageName))\n",
    "  image_array = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)\n",
    "  if normalize:\n",
    "    image_array = image_array/255\n",
    "    \n",
    "  return image_array\n",
    "\n",
    "# Extract the daata from 0 to amount from list and return it\n",
    "def CropData(list, amount):\n",
    "  if (len(list) < amount):\n",
    "    amount = len(list)\n",
    "  croppedList = list[:amount]\n",
    "  del list[:amount]\n",
    "  return croppedList\n",
    "\n",
    "def LoadImages(imagePath, list):\n",
    "  label = []\n",
    "  data = []\n",
    "  count = 0\n",
    "  for entries in list:\n",
    "    # try:\n",
    "      image = LoadImage(imagePath, entries[1])\n",
    "      data.append(image) \n",
    "      label.append(entries[0]) \n",
    "    # except: \n",
    "      # print(\"Failed to load training image: \", entries[1])\n",
    "  npLabel = np.array(label) \n",
    "  npData = np.array(data) \n",
    "  return npLabel, npData \n",
    "\n",
    "def InitializeModel():\n",
    "  pretrained_model = tf.keras.applications.MobileNetV3Large(input_shape=(224,224,3)) # Initializing model with mobile net V3 pretrained model\n",
    "\n",
    "  # Initializing the input and output from the model, removing last layer\n",
    "  base_input = pretrained_model.layers[0].input\n",
    "  base_output = pretrained_model.layers[-2].output\n",
    "\n",
    "  # Adding 3 more layers to output side\n",
    "  final_output = layers.Dense(128)(base_output) # Adding new layers, to the output side\n",
    "  final_output = layers.Activation('relu')(final_output) # activating layer\n",
    "  final_output = layers.Dense(64)(final_output)\n",
    "  final_output = layers.Activation('relu')(final_output) # activating layer\n",
    "  final_output = layers.Dense(8, activation = 'softmax')(final_output) # 8 cuz there are 8 image classifications\n",
    "\n",
    "  new_model = keras.Model(inputs = base_input, outputs = final_output)\n",
    "  # new_model.summary()\n",
    "  return new_model\n",
    "\n",
    "def ConvertToGray(image):\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "  return image\n",
    "\n",
    "def ScaleImage(image, width):\n",
    "  ratio = image.shape[1]/width\n",
    "  image = cv2.resize(image, (width, int(image.shape[0]/ratio)))\n",
    "  return image\n",
    "\n",
    "def DetectFace(image):\n",
    "  face_roi = np.ndarray(1)\n",
    "  faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "  grayImage = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "  faces = faceCascade.detectMultiScale(grayImage, 1.3, 5)\n",
    "  for x,y,w,h in faces:\n",
    "    roi_gray = grayImage[y:y+h, x:x+w]\n",
    "    roi_color = image[y:y+h, x:x+w]\n",
    "    cv2.rectangle(image, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "    facess = faceCascade.detectMultiScale(roi_gray)\n",
    "    if (len(facess) == 0):\n",
    "      print(\"Face not detected\")\n",
    "    else:\n",
    "      for (ex,ey,ew,eh) in facess:\n",
    "        face_roi = roi_color[ey:ey+eh, ex:ex+ew]\n",
    "  return face_roi\n",
    "\n",
    "def ConvertToInput(image):\n",
    "  input = ScaleImage(image, 224)\n",
    "  input = np.expand_dims(input, axis = 0) ## to add fourth dimension to fit model input\n",
    "  input = input/255\n",
    "  return input\n",
    "\n",
    "def GetResult(model, input):\n",
    "  Predictions = model.predict(input)\n",
    "  print(Predictions)\n",
    "  result = np.argmax(Predictions)\n",
    "  return emotionList[result]\n",
    "\n",
    "def printDataSetLabels(dataSet):\n",
    "    counterList = list(range(8))\n",
    "    for label, name in dataSet:\n",
    "        counterList[label] += 1\n",
    "    print(counterList)\n",
    "    \n",
    "# Reset Keras Session\n",
    "def reset_keras():\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    "\n",
    "    # try:\n",
    "    #     del classifier # this is from global space - change this as you need\n",
    "    # except:\n",
    "    #     pass\n",
    "\n",
    "    # use the same config as you used to create the session\n",
    "    tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.9, visible_device_list=\"0\")\n",
    "    \n",
    "def TestModel(model, testSetData):\n",
    "  # test model\n",
    "  lostSum = 0\n",
    "  accuracySum = 0\n",
    "  count = 0\n",
    "  while(len(testSetData) != 0):\n",
    "    # training data\n",
    "    try:\n",
    "      croppedList = CropData(testSetData, 100)\n",
    "      label, data = LoadImages(TESTIMAGEPATH, croppedList)\n",
    "      result = model.evaluate(data, label, batch_size = 1)\n",
    "      lostSum += result[0]\n",
    "      accuracySum += result[1]\n",
    "    except:\n",
    "      print(\"Failed to test data\")\n",
    "\n",
    "    count += 1\n",
    "    reset_keras()\n",
    "  \n",
    "  return lostSum/count, accuracySum/count\n",
    "\n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "  def on_train_begin(self, logs={}):\n",
    "    self.times = []\n",
    "\n",
    "  def on_epoch_begin(self, batch, logs={}):\n",
    "    self.epoch_time_start = time.time()\n",
    "\n",
    "  def on_epoch_end(self, batch, logs={}):\n",
    "    self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "  def AverageTime(self):\n",
    "    sum = 0\n",
    "    for time in self.times:\n",
    "      sum += time\n",
    "    return sum/len(self.times)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files loaded:10000\n",
      "Files loaded:20000\n",
      "Files loaded:30000\n",
      "Total images loaded:  31553\n",
      "Images Loaded:  [4000, 4000, 4000, 4000, 4000, 3803, 4000, 3750]\n",
      "Total images loaded:  3999\n",
      "Images Loaded:  [500, 500, 500, 500, 500, 500, 500, 499]\n"
     ]
    }
   ],
   "source": [
    "mainTrainSet = LoadAllImageNames(TRAINIMAGEPATH, catLimit=[4000]*8)\n",
    "mainTestSet = LoadAllImageNames(TESTIMAGEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset learning rate callback to counter ReduceLROnPlateau\n",
    "class ResetLR(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, learningRate):\n",
    "        self.default_lr = learningRate\n",
    "    def on_train_begin(self, logs={}):\n",
    "        previous_lr = self.model.optimizer.lr.read_value()\n",
    "        if previous_lr != self.default_lr:\n",
    "            print(\"Resetting learning rate from {} to {}\".format(previous_lr, self.default_lr))\n",
    "            self.model.optimizer.lr.assign(self.default_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model prepping\n",
    "Change the pretrained model and layers here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DoubleLayerTrainAndTest(modelName, epoch, learningRate, batchSize, firstLayerSize, secondLayerSize):\n",
    "  \"\"\"Train and test a model. This function's input should be customized to accept different parameters, function body should be customized to these parameters to train models of variety of paramters.\n",
    "\n",
    "  Args:\n",
    "      modelName (str): name of model\n",
    "  \"\"\"\n",
    "  pretrained_model = tf.keras.applications.MobileNetV3Small(input_shape=(224,224,3)) # Initializing model with mobile net V3 pretrained model\n",
    "\n",
    "  # Initializing the input and output from the model, removing last layer\n",
    "  base_input = pretrained_model.layers[0].input\n",
    "  base_output = pretrained_model.layers[-2].output\n",
    "\n",
    "  # Freeze layer\n",
    "  pretrained_model.trainable = False\n",
    "  for layer in pretrained_model.layers:\n",
    "    assert layer.trainable == False\n",
    "    layer.trainable = False\n",
    "\n",
    "  #-------------------------------------------------\n",
    "  # Customizing layers\n",
    "  #-------------------------------------------------\n",
    "  # Adding 3 more layers to output side\n",
    "  final_output = layers.Dense(firstLayerSize)(base_output) # Adding new layers, to the output side\n",
    "  final_output = layers.Activation('relu')(final_output) # activating layer\n",
    "  final_output = layers.Dense(secondLayerSize)(final_output) # Adding new layers, to the output side\n",
    "  final_output = layers.Activation('relu')(final_output) # activating layer\n",
    "  final_output = layers.Dense(8, activation = 'softmax')(final_output) # 8 cuz there are 8 image classifications\n",
    "\n",
    "  model = keras.Model(inputs = base_input, outputs = final_output)\n",
    "  model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = keras.optimizers.Adam(lr = learningRate), metrics=[\"accuracy\"])\n",
    "\n",
    "  # ------------------ Callbacks ------------------\n",
    "  # earlyStop = EarlyStopping(monitor='val_loss', patience = 3, restore_best_weights = True)\n",
    "  # earlyStopAcc = EarlyStopping(monitor='val_accuracy', patience = 1, restore_best_weights = True)\n",
    "  # reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = 1, min_lr = 0.0002)\n",
    "  # reset_lr = ResetLR(learningRate)\n",
    "    \n",
    "  # ------------------ Training Model ------------------\n",
    "  time_callback = TimeHistory()\n",
    "  dataSet = mainTrainSet.copy()\n",
    "\n",
    "  # Initializing model fit params\n",
    "  # batchSize = 4\n",
    "  imgPerIter = batchSize*32\n",
    "\n",
    "  count = 0\n",
    "  iter = 0\n",
    "  while(len(dataSet) != 0):\n",
    "    iter += 1\n",
    "    croppedList = []\n",
    "    tensorboard = TensorBoard(log_dir = \"logs/{}_it{}\".format(modelName, iter))\n",
    "    try:\n",
    "      print(\"loading image\") # Crop and load images in\n",
    "      croppedList = CropData(dataSet, imgPerIter)\n",
    "      label, data = LoadImages(TRAINIMAGEPATH, croppedList)\n",
    "      # Training model\n",
    "      model.fit(data, label, epochs = epoch, validation_split = 0.2, batch_size = batchSize, callbacks = [time_callback, tensorboard])\n",
    "      print(time_callback.AverageTime())\n",
    "    except RuntimeError as e:\n",
    "      print(e)\n",
    "    \n",
    "    # Saving weights\n",
    "    model.save_weights('{}.h5'.format(modelName))\n",
    "    \n",
    "    # Print summary of current iteration\n",
    "    count = count + len(croppedList)\n",
    "    timeLeft = len(dataSet)/imgPerIter * time_callback.AverageTime()\n",
    "    print(\"trained image count: \", count)\n",
    "    print(\"Images Left: \", len(dataSet))\n",
    "    print(\"Estimated completion time: \", str(timedelta(seconds=timeLeft)))\n",
    "    \n",
    "    reset_keras()\n",
    "  print(\"---------------- {} Training Completed ------------------\".format(modelName))\n",
    "\n",
    "  # ---------------- Testing Model -----------------\n",
    "  # initialise image names and label\n",
    "\n",
    "  # test model\n",
    "  loss, accuracy = TestModel(model, mainTestSet.copy())\n",
    "  \n",
    "  # Saving test informations\n",
    "  modelSummary = '''\n",
    "  model name: {}\n",
    "  average lost: {}\n",
    "  average accuracy: {}\n",
    "            '''.format(modelName, loss, accuracy)\n",
    "      \n",
    "  print(\"==========FINISH TESTING===========\\n{}\".format(modelSummary))\n",
    "  \n",
    "  file = open(\"training_summaries.txt\", \"a\")\n",
    "  file.write(modelSummary + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j.teoh\\AppData\\Local\\miniconda3\\envs\\tflite-facial-expression\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading image\n",
      "Epoch 1/13\n",
      "26/26 [==============================] - 11s 293ms/step - loss: 2.1178 - accuracy: 0.1352 - val_loss: 2.0797 - val_accuracy: 0.1039\n",
      "Epoch 2/13\n",
      "26/26 [==============================] - 7s 284ms/step - loss: 2.0797 - accuracy: 0.1311 - val_loss: 2.0796 - val_accuracy: 0.1039\n",
      "Epoch 3/13\n",
      "26/26 [==============================] - 7s 288ms/step - loss: 2.0790 - accuracy: 0.1319 - val_loss: 2.0796 - val_accuracy: 0.1039\n",
      "Epoch 4/13\n",
      "26/26 [==============================] - 7s 283ms/step - loss: 2.0786 - accuracy: 0.1360 - val_loss: 2.0796 - val_accuracy: 0.1234\n",
      "Epoch 5/13\n",
      "26/26 [==============================] - 7s 281ms/step - loss: 2.0783 - accuracy: 0.1474 - val_loss: 2.0795 - val_accuracy: 0.1234\n",
      "Epoch 6/13\n",
      "26/26 [==============================] - 7s 278ms/step - loss: 2.0780 - accuracy: 0.1474 - val_loss: 2.0795 - val_accuracy: 0.1234\n",
      "Epoch 7/13\n",
      "26/26 [==============================] - 7s 281ms/step - loss: 2.0777 - accuracy: 0.1474 - val_loss: 2.0796 - val_accuracy: 0.1234\n",
      "Epoch 8/13\n",
      "26/26 [==============================] - 7s 284ms/step - loss: 2.0775 - accuracy: 0.1474 - val_loss: 2.0796 - val_accuracy: 0.1234\n",
      "Epoch 9/13\n",
      "26/26 [==============================] - 7s 286ms/step - loss: 2.0772 - accuracy: 0.1474 - val_loss: 2.0796 - val_accuracy: 0.1234\n",
      "Epoch 10/13\n",
      "26/26 [==============================] - 7s 284ms/step - loss: 2.0770 - accuracy: 0.1474 - val_loss: 2.0797 - val_accuracy: 0.1234\n",
      "Epoch 11/13\n",
      "26/26 [==============================] - 7s 288ms/step - loss: 2.0769 - accuracy: 0.1474 - val_loss: 2.0798 - val_accuracy: 0.1234\n",
      "Epoch 12/13\n",
      "26/26 [==============================] - 7s 281ms/step - loss: 2.0767 - accuracy: 0.1474 - val_loss: 2.0799 - val_accuracy: 0.1234\n",
      "Epoch 13/13\n",
      "26/26 [==============================] - 7s 285ms/step - loss: 2.0765 - accuracy: 0.1474 - val_loss: 2.0800 - val_accuracy: 0.1234\n",
      "7.628403186798096\n",
      "trained image count:  1536\n",
      "Images Left:  30017\n",
      "Estimated completion time:  0:02:29.076679\n",
      "loading image\n",
      "Epoch 1/13\n",
      "26/26 [==============================] - 8s 285ms/step - loss: 2.0801 - accuracy: 0.1295 - val_loss: 2.0797 - val_accuracy: 0.1201\n",
      "Epoch 2/13\n",
      "26/26 [==============================] - 7s 284ms/step - loss: 2.0798 - accuracy: 0.1295 - val_loss: 2.0799 - val_accuracy: 0.1201\n",
      "Epoch 3/13\n",
      "26/26 [==============================] - 7s 281ms/step - loss: 2.0794 - accuracy: 0.1295 - val_loss: 2.0803 - val_accuracy: 0.1201\n",
      "Epoch 4/13\n",
      "26/26 [==============================] - 7s 280ms/step - loss: 2.0791 - accuracy: 0.1295 - val_loss: 2.0804 - val_accuracy: 0.1201\n",
      "Epoch 5/13\n",
      "26/26 [==============================] - 7s 282ms/step - loss: 2.0788 - accuracy: 0.1295 - val_loss: 2.0809 - val_accuracy: 0.1201\n",
      "Epoch 6/13\n",
      "26/26 [==============================] - 7s 283ms/step - loss: 2.0786 - accuracy: 0.1295 - val_loss: 2.0812 - val_accuracy: 0.1201\n",
      "Epoch 7/13\n",
      "26/26 [==============================] - 7s 281ms/step - loss: 2.0785 - accuracy: 0.1295 - val_loss: 2.0813 - val_accuracy: 0.1201\n",
      "Epoch 8/13\n",
      "26/26 [==============================] - 7s 281ms/step - loss: 2.0782 - accuracy: 0.1295 - val_loss: 2.0816 - val_accuracy: 0.1201\n",
      "Epoch 9/13\n",
      "26/26 [==============================] - 7s 283ms/step - loss: 2.0781 - accuracy: 0.1295 - val_loss: 2.0819 - val_accuracy: 0.1201\n",
      "Epoch 10/13\n",
      "26/26 [==============================] - 7s 279ms/step - loss: 2.0779 - accuracy: 0.1295 - val_loss: 2.0820 - val_accuracy: 0.1201\n",
      "Epoch 11/13\n",
      "26/26 [==============================] - 7s 280ms/step - loss: 2.0778 - accuracy: 0.1295 - val_loss: 2.0823 - val_accuracy: 0.1201\n",
      "Epoch 12/13\n",
      "26/26 [==============================] - 7s 276ms/step - loss: 2.0777 - accuracy: 0.1295 - val_loss: 2.0825 - val_accuracy: 0.1201\n",
      "Epoch 13/13\n",
      "26/26 [==============================] - 7s 281ms/step - loss: 2.0776 - accuracy: 0.1295 - val_loss: 2.0828 - val_accuracy: 0.1201\n",
      "7.303674991314228\n",
      "trained image count:  3072\n",
      "Images Left:  28481\n",
      "Estimated completion time:  0:02:15.427062\n",
      "loading image\n",
      "Epoch 1/13\n",
      "26/26 [==============================] - 8s 284ms/step - loss: 2.0799 - accuracy: 0.1132 - val_loss: 2.0817 - val_accuracy: 0.1136\n",
      "Epoch 2/13\n",
      "26/26 [==============================] - 7s 280ms/step - loss: 2.0795 - accuracy: 0.1384 - val_loss: 2.0819 - val_accuracy: 0.1234\n",
      "Epoch 3/13\n",
      "26/26 [==============================] - 7s 282ms/step - loss: 2.0792 - accuracy: 0.1352 - val_loss: 2.0819 - val_accuracy: 0.1234\n",
      "Epoch 4/13\n",
      "26/26 [==============================] - 7s 286ms/step - loss: 2.0788 - accuracy: 0.1352 - val_loss: 2.0822 - val_accuracy: 0.1234\n",
      "Epoch 5/13\n",
      "26/26 [==============================] - 7s 280ms/step - loss: 2.0785 - accuracy: 0.1352 - val_loss: 2.0822 - val_accuracy: 0.1234\n",
      "Epoch 6/13\n",
      "26/26 [==============================] - 7s 281ms/step - loss: 2.0783 - accuracy: 0.1352 - val_loss: 2.0823 - val_accuracy: 0.1234\n",
      "Epoch 7/13\n",
      "26/26 [==============================] - 7s 277ms/step - loss: 2.0780 - accuracy: 0.1352 - val_loss: 2.0824 - val_accuracy: 0.1234\n",
      "Epoch 8/13\n",
      "26/26 [==============================] - 7s 275ms/step - loss: 2.0779 - accuracy: 0.1352 - val_loss: 2.0825 - val_accuracy: 0.1234\n",
      "Epoch 9/13\n",
      "14/26 [===============>..............] - ETA: 3s - loss: 2.0789 - accuracy: 0.1384"
     ]
    }
   ],
   "source": [
    "batchSizes = [48, 64, 96, 128]\n",
    "firstLayerSizes = [384, 516, 772]\n",
    "secondLayerSizes = [32, 48, 64, 96, 128]\n",
    "epoch = 13\n",
    "learningRate = 0.001\n",
    "\n",
    "for batchSize in batchSizes:\n",
    "    for firstLayerSize in firstLayerSizes:\n",
    "        for secondLayerSize in secondLayerSizes:\n",
    "            if firstLayerSize <= secondLayerSize:\n",
    "                continue\n",
    "            modelName = \"freezeCNN_{}epoch_{}lr_{}bs_{}L1_{}L2\".format(epoch, learningRate, batchSize, firstLayerSize, secondLayerSize)\n",
    "            DoubleLayerTrainAndTest(modelName, epoch, learningRate, batchSize, firstLayerSize, secondLayerSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default Train and Test function\n",
    "def TrainAndTest(modelName):\n",
    "  \"\"\"Train and test a model. This function's input should be customized to accept different parameters, function body should be customized to these parameters to train models of variety of paramters.\n",
    "\n",
    "  Args:\n",
    "      modelName (str): name of model\n",
    "  \"\"\"\n",
    "  pretrained_model = tf.keras.applications.MobileNetV3Large(input_shape=(224,224,3)) # Initializing model with mobile net V3 pretrained model\n",
    "\n",
    "  # Initializing the input and output from the model, removing last layer\n",
    "  base_input = pretrained_model.layers[0].input\n",
    "  base_output = pretrained_model.layers[-2].output\n",
    "\n",
    "  #-------------------------------------------------\n",
    "  # Customizing layers\n",
    "  #-------------------------------------------------\n",
    "  # Adding 3 more layers to output side\n",
    "  final_output = layers.Dense(128)(base_output) # Adding new layers, to the output side\n",
    "  final_output = layers.Activation('relu')(final_output) # activating layer\n",
    "  final_output = layers.Dense(8, activation = 'softmax')(final_output) # 8 cuz there are 8 image classifications\n",
    "\n",
    "  model = keras.Model(inputs = base_input, outputs = final_output)\n",
    "  model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "  # ------------------ Training Model ------------------\n",
    "  time_callback = TimeHistory()\n",
    "  dataSet = mainTrainSet.copy()\n",
    "\n",
    "  # Initializing model fit params\n",
    "  batchSize = 4\n",
    "  imgPerIter = batchSize*8\n",
    "\n",
    "  count = 0\n",
    "  while(len(dataSet) != 0):\n",
    "    croppedList = []\n",
    "    try:\n",
    "      print(\"loading image\") # Crop and load images in\n",
    "      croppedList = CropData(dataSet, imgPerIter)\n",
    "      label, data = LoadImages(TRAINIMAGEPATH, croppedList)\n",
    "      \n",
    "      # Training model\n",
    "      model.fit(data, label, epochs = 11, batch_size = batchSize, callbacks = [time_callback])\n",
    "      print(time_callback.AverageTime())\n",
    "    except RuntimeError as e:\n",
    "      print(e)\n",
    "    \n",
    "    # Saving weights\n",
    "    model.save_weights('{}.h5'.format(modelName))\n",
    "    \n",
    "    # Print summary of current iteration\n",
    "    count = count + len(croppedList)\n",
    "    timeLeft = len(dataSet)/imgPerIter * time_callback.AverageTime()\n",
    "    print(\"trained image count: \", count)\n",
    "    print(\"Images Left: \", len(dataSet))\n",
    "    print(\"Estimated completion time: \", str(timedelta(seconds=timeLeft)))\n",
    "    \n",
    "    reset_keras()\n",
    "  print(\"---------------- {} Training Completed ------------------\".format(modelName))\n",
    "\n",
    "  # ---------------- Testing Model -----------------\n",
    "  # initialise image names and label\n",
    "  testSetData = mainTrainSet.copy()\n",
    "\n",
    "  # test model\n",
    "  loss, accuracy = TestModel(model, mainTrainSet.copy())\n",
    "  \n",
    "  # Saving test informations\n",
    "  modelSummary = '''\n",
    "  model name: {}\n",
    "  average lost: {}\n",
    "  average accuracy: {}\n",
    "            '''.format(modelName, loss, accuracy)\n",
    "      \n",
    "  print(\"==========FINISH TESTING===========\\n{}\".format(modelSummary))\n",
    "  \n",
    "  file = open(\"training_summaries.txt\", \"a\")\n",
    "  file.write(modelSummary + \"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
